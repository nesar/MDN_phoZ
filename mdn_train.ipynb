{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras.models import load_model, Sequential, Model\n",
    "\n",
    "# Activate TF2 behavior:\n",
    "from tensorflow.python import tf2\n",
    "if not tf2.enabled():\n",
    "    import tensorflow.compat.v2 as tf\n",
    "    tf.enable_v2_behavior()\n",
    "    assert tf2.enabled()\n",
    "\n",
    "np.random.seed(12211)  \n",
    "\n",
    "# %load_ext line_profiler\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 1\n",
    "# %aimport help_train\n",
    "import help_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = True # False if you don't want to train again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 9999 # 10000, 4000 # Max: 200000 \n",
    "num_test = 1000 # 1000 # Max: 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainset = ['FSPSlin', 'FSPSlog', 'FSPSall', 'OBS', 'UM', 'BP', 'UMnew'][6] # Soon there will be more!\n",
    "# Testset = ['FSPSlin', 'FSPSlog', 'FSPSall', 'OBS', 'UM', 'BP', 'UMnew'][3]\n",
    "Testset = ['FSPSlin', 'FSPSlog', 'FSPSall', 'OBS', 'UM', 'BP', 'UMnew', 'OBSuq'][7] # Test on the same things we tested before (SDSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 20 # 100\n",
    "D = 5 #6  # number of features (in input space)\n",
    "K = 3 #16 # number of mixture components # a \"component\" of a GMM is one gaussian, right?\n",
    "\n",
    "learning_rate = 1e-4\n",
    "decay_rate= 1e-3\n",
    "batch_size = 1024\n",
    "\n",
    "# Here we define hyperparameters!\n",
    "save_mod = 'saved_hubs/tf2models/'+'Train_'+Trainset+'_lr_'+str(learning_rate)+'_dr'+str(decay_rate)+'_ne'+str(n_epochs)+'_k'+str(K)+'_nt'+str(num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "number of datapoints:  187462\n",
      "z-minmax:  0.0020016062 1.249997\n",
      "ColMag-min:  [-0.09145837 -0.05327791 -0.02479261 -0.10519464 12.000012  ]\n",
      "ColMag-max:  [ 3.825315   2.8303378  1.6937237  1.5019817 23.499979 ]\n",
      "----------\n",
      "----------\n",
      "number of datapoints:  10322\n",
      "z-minmax:  0.0020014732 1.249283\n",
      "ColMag-min:  [-4.1676056e-02 -7.1866615e-03  5.6203555e-02 -6.4645730e-02\n",
      "  1.2003667e+01]\n",
      "ColMag-max:  [ 3.6190994  2.7985296  1.6097487  1.4396983 23.4981   ]\n",
      "----------\n",
      "----------\n",
      "number of datapoints:  4339\n",
      "z-minmax:  7.926745e-06 7.01\n",
      "ColMag-min:  [ -5.188479   -3.8901405  -2.1034117 -15.92296    12.114799 ]\n",
      "ColMag-max:  [17.02884   7.925968  4.182415  2.264679 25.709858]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, _, _ = help_train.loadTrainTest_july(dirIn = '/data/a/cpac/nramachandra/Projects/phoZ/Data/fromGalaxev/photozs/datasets/data_july_2020/')\n",
    "X_test, y_test, X_err, label_test = help_train.loadTest(Testset, dirIn = '/data/a/cpac/aurora/MDN_phoZ/Data/fromGalaxev/photozs/datasets/data_feb_2021/') # data_feb_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_trainShuffleOrder = help_train.shuffle(X_train, y_train) # literally just shuffle the data\n",
    "# X_test, y_test, label_test, X_testShuffleOrder = shuffleOBS(X_test, y_test, test_labels) # Why aren't we doing this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_col = [-0.09145837, -0.05327791, -0.02479261, -0.10519464] #-0.03 #-5 # Same as what we got from print_limits\n",
    "max_col = [ 3.825315,   2.8303378,  1.6937237,  1.5019817] #3.4 #5\n",
    "min_mag = 12\n",
    "max_mag = 23\n",
    "min_z = 0.0 #np.min(y_train)\n",
    "max_z = 1.1 #np.max(y_train)\n",
    "\n",
    "mins_and_maxs = [min_col, max_col, min_mag, max_mag, min_z, max_z]\n",
    "\n",
    "X_test, y_test, label_test, mask_cond = help_train.minmax_cutsOBSarr(X_test, y_test, label_test, mins_and_maxs) # Make sure all our data falls within the desired range (and bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79600,)\n"
     ]
    }
   ],
   "source": [
    "# Notice, this cell is recursive. (If you run it multiple times, the resulting plot will change)\n",
    "resampleTrain = True\n",
    "n_bins = 200 \n",
    "select_per_bin = 400 # 500, 50\n",
    "\n",
    "if resampleTrain:\n",
    "    X_train, y_train, resampled_ind = help_train.resample(X_train, y_train, n_bins, select_per_bin) # What is \"rest\"? And where did the original data go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of features in training data: (79600, 5)\n",
      "Size of output in training data: (79600,)\n",
      "Size of features in test data: (2767, 5)\n",
      "Size of output in test data: (2767,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of features in training data: {}\".format(X_train.shape)) # what do we mean features?\n",
    "print(\"Size of output in training data: {}\".format(y_train.shape))\n",
    "print(\"Size of features in test data: {}\".format(X_test.shape))\n",
    "print(\"Size of output in test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously, we said \"this notebook doesn't train models, it deploys them\"\n",
    "# Now, we are training models (I think?)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# This preproc stuff is related to \"scaling routine\" -- right? Yes :)\n",
    "preproc = Pipeline([('stdscaler', StandardScaler())]) # This preproc tool is what allows us to transform inputs into min-max space (and therefore to feed it to the trained model)\n",
    "# preproc = Pipeline([('stdscaler', MinMaxScaler())])\n",
    "X_train = preproc.fit_transform(X_train) # Not sure how \"fit_transform\" is different from the original \"transform\"?\n",
    "\n",
    "scalerfile = save_mod + '_scaling_X'\n",
    "pickle.dump(preproc, open(scalerfile, 'wb'))\n",
    "preproc = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "X_test = preproc.transform(X_test) # This transformation puts our input into min-max space\n",
    "\n",
    "# preproc_y = Pipeline([('stdscaler', StandardScaler())])\n",
    "preproc_y = Pipeline([('stdscaler', MinMaxScaler())])\n",
    "\n",
    "y_train = preproc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "scalerfile = save_mod + '_scaling_y'\n",
    "pickle.dump(preproc_y, open(scalerfile, 'wb'))\n",
    "preproc_y = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "y_test = preproc_y.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "number of datapoints:  79600\n",
      "z-minmax:  0.0 1.0000001\n",
      "ColMag-min:  [-1.6507052 -2.2788894 -2.3348138 -2.2950504 -4.2421055]\n",
      "ColMag-max:  [4.724002  4.212091  3.5302377 3.8734057 1.2678376]\n",
      "----------\n",
      "----------\n",
      "number of datapoints:  2767\n",
      "z-minmax:  -0.0015975338 0.8793446\n",
      "ColMag-min:  [-1.6387041 -2.2345772 -2.3220117 -2.3038087 -4.1878986]\n",
      "ColMag-max:  [4.745621  4.1498146 3.6145232 3.919013  1.0281243]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "help_train.print_limits(X_train, y_train)\n",
    "\n",
    "help_train.print_limits(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# That is a very messy histogram :P Looks like the precision on test is much lower than on train?\n",
    "plt.figure(23)\n",
    "\n",
    "plt.hist(y_train, density=True, bins = 250, histtype='step', label='train')\n",
    "plt.hist(y_test, density=True, bins = 250, histtype='step', label='test')\n",
    "plt.legend()\n",
    "plt.savefig(\"precision\" + str(num_train) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLR(tf.keras.callbacks.Callback): # Print learning rate at every epoch\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1, model_train.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay_rate),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the network parameters!! (This whole cell is network architecture)\n",
    "\n",
    "# x = tf.keras.layers.InputLayer(input_shape=(D,)),\n",
    "non_lin_act = tf.nn.relu #tf.nn.tanh\n",
    "y_true = tf.keras.Input(shape=(1,))\n",
    "inputs = tf.keras.Input(shape=(D,))\n",
    "layer_1 = tf.keras.layers.Dense(units=512, activation=non_lin_act)(inputs)\n",
    "layer_1a = tf.keras.layers.Dense(units=1024, activation=non_lin_act)(layer_1)\n",
    "layer_1b = tf.keras.layers.Dense(units=2048, activation=non_lin_act)(layer_1a)\n",
    "layer_1c = tf.keras.layers.Dense(units=1024, activation=non_lin_act)(layer_1b)\n",
    "layer_2 = tf.keras.layers.Dense(units=512, activation=non_lin_act)(layer_1c)\n",
    "layer_3 = tf.keras.layers.Dense(units=256, activation=non_lin_act)(layer_2)\n",
    "layer_4 = tf.keras.layers.Dense(units=128, activation=non_lin_act)(layer_3)\n",
    "layer_5 = tf.keras.layers.Dense(units=64, activation=non_lin_act)(layer_4)\n",
    "layer_6 = tf.keras.layers.Dense(units=32, activation=non_lin_act)(layer_5)\n",
    "mu = tf.keras.layers.Dense(units=K, activation=None, name=\"mu\")(layer_6)\n",
    "var = tf.keras.backend.exp(tf.keras.layers.Dense(units=K, activation=tf.nn.softplus, name=\"sigma\")(layer_6))\n",
    "pi = tf.keras.layers.Dense(units=K, activation=tf.nn.softmax, name=\"mixing\")(layer_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = Model([inputs, y_true], [mu, var, pi], name='mdn') # Previously, this was the mixed density model (is that the same as a Gaussian mixture model?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mdn\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          3072        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         525312      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         2099200     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          524800      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          131328      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           8256        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           2080        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sigma (Dense)                   (None, 3)            99          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 3)            99          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 3)            0           sigma[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mixing (Dense)                  (None, 3)            99          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (1, None)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_3 (TFOpLam (1, None)            0           tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_4 (TFOpLam (1, None)            0           tf.convert_to_tensor_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (2,)                 0           tf.convert_to_tensor_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_5 (TFOpLam (2,)                 0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (2,)                 0           tf.convert_to_tensor_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (0,)                 0           tf.convert_to_tensor_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (3,)                 0           tf.__operators__.getitem[0][0]   \n",
      "                                                                 tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (1, None, 1)         0           tf.convert_to_tensor_3[0][0]     \n",
      "                                                                 tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_2 (TFOpLam (None, 3)            0           tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_6 (TFOpLam (1, None, 1)         0           tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_7 (TFOpLam (None, 3)            0           tf.convert_to_tensor_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_1 (TFOpLam (None, 3)            0           mu[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (1, None, 3)         0           tf.convert_to_tensor_6[0][0]     \n",
      "                                                                 tf.convert_to_tensor_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_1 (TFOpLambda)  (None, 3)            0           tf.convert_to_tensor_1[0][0]     \n",
      "                                                                 tf.convert_to_tensor_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.squared_difference (TFO (1, None, 3)         0           tf.math.truediv[0][0]            \n",
      "                                                                 tf.math.truediv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.log (TFOpLambda)        (None, 3)            0           tf.convert_to_tensor_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (None, 3)            0           mixing[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (1, None, 3)         0           tf.math.squared_difference[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 3)            0           tf.math.log[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.log_1 (TFOpLambda)      (None, 3)            0           tf.convert_to_tensor[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (1, None, 3)         0           tf.math.multiply[0][0]           \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.log_softmax (TFOpLambda)  (None, 3)            0           tf.math.log_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (1, None, 3)         0           tf.math.subtract[0][0]           \n",
      "                                                                 tf.nn.log_softmax[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_logsumexp (TFOpL (1, None)            0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (1, None)            0           tf.math.reduce_logsumexp[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda ()                   0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf.math.reduce_mean[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 5,425,417\n",
      "Trainable params: 5,425,417\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define custom loss\n",
    "def custom_loss(layer):\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true, mu, var, pi):\n",
    "        mixture_distribution = tfp.distributions.Categorical(probs=pi)\n",
    "        distribution = tfp.distributions.Normal(loc=mu, scale=var)\n",
    "        likelihood = tfp.distributions.MixtureSameFamily(mixture_distribution=mixture_distribution,components_distribution=distribution)\n",
    "\n",
    "        log_likelihood = -1.0*likelihood.log_prob(tf.transpose(y_true)) # A little confusing (talk later)\n",
    "        mean_loss = tf.reduce_mean(log_likelihood)\n",
    "\n",
    "        return mean_loss  \n",
    "    return loss\n",
    "    \n",
    "model_train.add_loss(custom_loss(inputs)(y_true, mu, var, pi))\n",
    "model_train.compile(optimizer='Nadam')\n",
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1904\u001b[0m       \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m       \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1906\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Support for old API for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1088\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1905\u001b[0m       \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Support for old API for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1907\u001b[0;31m       \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1908\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m       raise ValueError('The output of the \"schedule\" function '\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if train_mode:\n",
    "\n",
    "    history = model_train.fit([X_train, y_train], validation_split = 0.1, epochs=n_epochs, batch_size = batch_size, callbacks=callbacks) # What's this history about?\n",
    "    # The problem is in the above line\n",
    "    model_train.save_weights(save_mod + '.h5')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], 'r')\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.xlabel('Epochs', fontsize = 28)\n",
    "    plt.ylabel('Loss', fontsize = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'saved_hubs/tf2models/Train_UMnew_lr_0.0001_dr0.001_ne20_k3_nt9999.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-872658570ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_mod\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Previously, this exact line was loading the weights of (from?) the mixed density model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2225\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2226\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2227\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'saved_hubs/tf2models/Train_UMnew_lr_0.0001_dr0.001_ne20_k3_nt9999.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model_train.load_weights(save_mod + '.h5') # Previously, this exact line was loading the weights of (from?) the mixed density model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(model_train(X_test))\n",
    "\n",
    "y_pred_arg = np.argmax(y_pred[2, :, :], axis = 1)\n",
    "y_pred_mean = y_pred[0, :, :][:, y_pred_arg][:, 0]\n",
    "y_pred_std = np.sqrt(np.log(y_pred[1, :, :][:, y_pred_arg][:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3means = preproc_y.inverse_transform(y_pred[0, :, :]) # Previously, we used preproc_y to pick the best Gaussian (of the three that make up the Gaussian mixture model)\n",
    "y_pred_3std = preproc_y.inverse_transform( np.sqrt(np.log(y_pred[1, :, :])  ))\n",
    "y_pred_3weights = y_pred[2, :, :]\n",
    "\n",
    "y_test_all = preproc_y.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "predstdweights = np.array([y_pred_3means, y_pred_3std, y_pred_3weights])\n",
    "truelabel = np.array([y_test_all[:, 0], label_test])\n",
    "\n",
    "np.save(save_mod+'test_true', predstdweights )\n",
    "np.save(save_mod+'test_pred', truelabel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifPlotWeighted = True\n",
    "y_pred_mean_best = y_pred_mean # So I've never understood this part. How do we know it's the best? And if it's always been the best, why didn't we call it the best from the beginning?\n",
    "y_pred_std_best = y_pred_std   # No good answer ;) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10,)) # How does this work (or conflict) with plt.figure() down below?\n",
    "if ifPlotWeighted:\n",
    "\n",
    "    colorstring = ['b', 'r', 'g', 'k', 'orange']\n",
    "    surveystring = ['SDSS', 'VIPERS', 'DEEP2']\n",
    "\n",
    "    plt.figure(22, figsize=(10, 10,))\n",
    "\n",
    "    C = 0.05\n",
    "    z_t = np.array([0, 1])\n",
    "    z_tp = z_t + C*(1+z_t)\n",
    "    z_tm = z_t - C*(1+z_t)\n",
    "\n",
    "    ax.plot(z_t, z_t, 'k')\n",
    "    ax.plot(z_t, z_tp, 'k-.')\n",
    "    ax.plot(z_t, z_tm, 'k-.')\n",
    "\n",
    "    for label_ind in [0, 1, 2]:\n",
    "        surveyindx = np.where(label_test == label_ind)\n",
    "        offset = 0.0\n",
    "        \n",
    "        ax.errorbar(preproc_y.inverse_transform(y_test)[surveyindx][:, 0], offset + preproc_y.inverse_transform(y_pred_mean_best.reshape(-1, 1))[surveyindx][:, 0], yerr= preproc_y.inverse_transform(y_pred_std_best.reshape(-1, 1))[surveyindx][:, 0], fmt = 'o', marker=None, ms = 4, alpha = 0.3, label = 'Training: Synthetic, Testing: '+surveystring[label_ind], c = colorstring[label_ind])\n",
    "\n",
    "ax.set_ylabel(r'$z_{phot}$', fontsize=25)\n",
    "ax.set_xlabel(r'$z_{spec}$', fontsize=25)\n",
    "        \n",
    "ax.set_xlim(0.0, 1)\n",
    "ax.set_ylim(0.0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.axes().set_aspect('equal')\n",
    "\n",
    "leg1 = ax.legend(fontsize = 'xx-large', markerscale=1., numpoints=2)\n",
    "fake_lines = [ax.plot([], [], c = \"black\")[0] for i in range(0,10)]\n",
    "print(fake_lines)\n",
    "param_labels = [\"num_train: \" + str(num_train), \"num_test: \" + str(num_test), \"n_epochs: \" + str(n_epochs), \"D: \" + str(D), \"K: \" + str(K), \"decay_rate: \" + str(decay_rate), \"batch_size: \" + str(batch_size), \"n_bins: \" + str(n_bins), \"select_per_bin: \" + str(select_per_bin)]\n",
    "ax.legend(handles = fake_lines, labels = param_labels, loc = \"upper left\")\n",
    "ax.add_artist(leg1)\n",
    "#fig.savefig('phoz_compare_surveys_numtrain_' + str(num_train) + '.pdf', bbox_inches='tight')\n",
    "fig.savefig(\"phoz_ntrain\" + str(num_train) + \".png\")\n",
    "fig.show()\n",
    "# num train, num test, n epochs, D, K, learning rate, decay rate, batch size, nbins, select per bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
