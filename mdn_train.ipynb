{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras.models import load_model, Sequential, Model\n",
    "\n",
    "# Activate TF2 behavior:\n",
    "from tensorflow.python import tf2\n",
    "if not tf2.enabled():\n",
    "  import tensorflow.compat.v2 as tf\n",
    "  tf.enable_v2_behavior()\n",
    "  assert tf2.enabled()\n",
    "\n",
    "np.random.seed(12211)  \n",
    "\n",
    "# import SetPub\n",
    "# SetPub.set_pub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 4000 #200000 \n",
    "num_test = 1000 #20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainset = ['FSPSlin', 'FSPSlog', 'FSPSall', 'OBS', 'UM', 'BP', 'UMnew'][6]\n",
    "# Testset = ['FSPSlin', 'FSPSlog', 'FSPSall', 'OBS', 'UM', 'BP', 'UMnew'][3]\n",
    "Testset = ['FSPSlin', 'FSPSlog', 'FSPSall', 'OBS', 'UM', 'BP', 'UMnew', 'OBSuq'][7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "D = 5 #6  # number of features  (8 for DES, 6 for COSMOS)\n",
    "K = 3 #16 # number of mixture components\n",
    "\n",
    "learning_rate = 1e-4\n",
    "decay_rate= 1e-3 \n",
    "batch_size = 1024 \n",
    "\n",
    "save_mod = 'saved_hubs/tf2models/'+'Train_'+Trainset+'_lr_'+str(learning_rate)+'_dr'+str(decay_rate)+'_ne'+str(n_epochs)+'_k'+str(K)+'_nt'+str(num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_cuts(X, y):\n",
    "    \n",
    "    mask_cond =  np.where( \n",
    "        (X[:, 0] < max_col) & (X[:, 0] > min_col) &\n",
    "        (X[:, 1] < max_col) & (X[:, 1] > min_col) &\n",
    "        (X[:, 2] < max_col) & (X[:, 2] > min_col) &\n",
    "        (X[:, 3] < max_col) & (X[:, 3] > min_col) & \n",
    "        (X[:, 4] < max_mag) & (X[:, 4] > min_mag) &\n",
    "        (y < max_z) & (y > min_z) )\n",
    "    \n",
    "    X_new = X[mask_cond]\n",
    "    y_new = y[mask_cond]\n",
    "    return X_new, y_new, mask_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_cutsOBSarr(X, y, l):\n",
    "    \n",
    "    mask_cond =  np.where( \n",
    "        (X[:, 0] < max_col[0]) & (X[:, 0] > min_col[0]) &\n",
    "        (X[:, 1] < max_col[1]) & (X[:, 1] > min_col[1]) &\n",
    "        (X[:, 2] < max_col[2]) & (X[:, 2] > min_col[2]) &\n",
    "        (X[:, 3] < max_col[3]) & (X[:, 3] > min_col[3]) & \n",
    "        (X[:, 4] < max_mag) & (X[:, 4] > min_mag) &\n",
    "        (y < max_z) & (y > min_z) )\n",
    "    \n",
    "\n",
    "    X_new = X[mask_cond]\n",
    "    y_new = y[mask_cond]\n",
    "    l_new = l[mask_cond]\n",
    "    return X_new, y_new, l_new, mask_cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_limits(X, y):\n",
    "    print(10*'-')\n",
    "    print('number of datapoints: ', str(y.shape[0]))\n",
    "    print('z-minmax: ', y.min(), y.max())\n",
    "    print('ColMag-min: ', np.min(X, axis=0))\n",
    "    print('ColMag-max: ', np.max(X, axis=0))\n",
    "    print(10*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    shuffleOrder = np.arange(X.shape[0])\n",
    "    np.random.shuffle(shuffleOrder)\n",
    "    X = X[shuffleOrder]\n",
    "    y = y[shuffleOrder]\n",
    "    return X, y, shuffleOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffleOBS(X, y, l):\n",
    "    shuffleOrder = np.arange(X.shape[0])\n",
    "    np.random.shuffle(shuffleOrder)\n",
    "    X = X[shuffleOrder]\n",
    "    y = y[shuffleOrder]\n",
    "    l = l[shuffleOrder]\n",
    "    return X, y, l, shuffleOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(X, y, n_bins = 200):\n",
    "\n",
    "    select_per_bin = 50 # 50 #np.int(num_train/n_bins) #100\n",
    "\n",
    "    bins = np.linspace(y.min(), y.max(), n_bins)\n",
    "    # bins = np.logspace(np.log10(y_test.min()+1e-2), np.log10(y_test.max()+1e-2), n_bins)\n",
    "    inds = np.digitize(y, bins)\n",
    "\n",
    "    resampled_ind = []\n",
    "\n",
    "    for ind_i in range(n_bins):\n",
    "        ind_bin = np.where(inds==ind_i)\n",
    "        random_choices = np.min( [select_per_bin, np.size(ind_bin) ])\n",
    "        index = np.random.choice(ind_bin[0], random_choices, replace=False)\n",
    "        resampled_ind = np.append(resampled_ind, index)\n",
    "\n",
    "    resampled_ind = resampled_ind.astype('int')\n",
    "    all_ind = np.arange(y.shape[0])\n",
    "    # resampled_ind_not = ~np.in1d(np.arange(all_ind.shape[-1]), resampled_ind)\n",
    "\n",
    "    plt.figure(23)\n",
    "    plt.hist(y, density=True, bins = n_bins, histtype='step', label='original')\n",
    "    y_resampled = y[resampled_ind]\n",
    "    X_resampled = X[resampled_ind]\n",
    "\n",
    "\n",
    "    plt.hist(y_resampled, density=True, bins = n_bins, histtype='step', label='resampled')\n",
    "    plt.hist(y_train, density=True, bins = n_bins, histtype='step', label='rest')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(y_resampled.shape)\n",
    "    \n",
    "    return X_resampled, y_resampled, resampled_ind\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainTest_july(dirIn = '../../Data/fromGalaxev/photozs/datasets/data_july_2020/'):\n",
    "\n",
    "\n",
    "    # train_data = np.load(dirIn + 'july13_100k.npy') \n",
    "    train_data = np.load(dirIn + 'july14_200k.npy') \n",
    "    test_data = np.load(dirIn + 'july13_10k.npy') \n",
    "    \n",
    "\n",
    "\n",
    "    X_train = train_data['color']#[train_data['redshift_flags'] == 0]\n",
    "    y_train = train_data['redshift']#[train_data['redshift_flags'] == 0]\n",
    "\n",
    "    # data['colors'] #  colors (ngal, ncols)\n",
    "    # data['redshifts'] # redshifts\n",
    "\n",
    "    X_test = test_data['color']#[test_data['redshift_flags'] == 0]\n",
    "    y_test = test_data['redshift']#[test_data['redshift_flags'] == 0]\n",
    "\n",
    "    print_limits(X_train, y_train)\n",
    "    print_limits(X_test, y_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# X_train, y_train, _, _ = loadTrainTest_july(dirIn = '../../Data/fromGalaxev/photozs/datasets/data_july_2020/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTest(dirIn = '../../Data/fromGalaxev/photozs/datasets/data_feb_2021/'):\n",
    "    \n",
    "    test_data = np.load(dirIn + 'test_' + Testset + '.npy') \n",
    "\n",
    "    X_test = test_data[: , :-1]\n",
    "    y_test = test_data[: , -1]\n",
    "\n",
    "    print_limits(X_test, y_test)\n",
    "\n",
    "    X_err = np.load(dirIn + 'test_' + Testset +'_err.npy') \n",
    "    test_labels = np.load(dirIn + 'test_' + Testset + '_label.npy') \n",
    "\n",
    "    return X_test, y_test, X_err, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "number of datapoints:  187462\n",
      "z-minmax:  0.0020016062 1.249997\n",
      "ColMag-min:  [-0.09145837 -0.05327791 -0.02479261 -0.10519464 12.000012  ]\n",
      "ColMag-max:  [ 3.825315   2.8303378  1.6937237  1.5019817 23.499979 ]\n",
      "----------\n",
      "----------\n",
      "number of datapoints:  10322\n",
      "z-minmax:  0.0020014732 1.249283\n",
      "ColMag-min:  [-4.1676056e-02 -7.1866615e-03  5.6203555e-02 -6.4645730e-02\n",
      "  1.2003667e+01]\n",
      "ColMag-max:  [ 3.6190994  2.7985296  1.6097487  1.4396983 23.4981   ]\n",
      "----------\n",
      "----------\n",
      "number of datapoints:  4339\n",
      "z-minmax:  7.926745e-06 7.01\n",
      "ColMag-min:  [ -5.188479   -3.8901405  -2.1034117 -15.92296    12.114799 ]\n",
      "ColMag-max:  [17.02884   7.925968  4.182415  2.264679 25.709858]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train, _, _ = loadTrainTest_july(dirIn = '../../Data/fromGalaxev/photozs/datasets/data_july_2020/')\n",
    "# X_test, y_test, X_err, label_test = loadTest(dirIn = '../../Data/fromGalaxev/photozs/datasets/data_feb_2021/')\n",
    "\n",
    "X_train, y_train, _, _ = loadTrainTest_july(dirIn = '/data/a/cpac/nramachandra/Projects/phoZ/Data/fromGalaxev/photozs/datasets/data_july_2020/')\n",
    "X_test, y_test, X_err, label_test = loadTest(dirIn = '/data/a/cpac/aurora/MDN_phoZ/Data/fromGalaxev/photozs/datasets/data_feb_2021/') # data_feb_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_trainShuffleOrder = shuffle(X_train, y_train)\n",
    "# X_test, y_test, label_test, X_testShuffleOrder = shuffleOBS(X_test, y_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_col = [-0.09145837, -0.05327791, -0.02479261, -0.10519464] #-0.03 #-5\n",
    "max_col = [ 3.825315,   2.8303378,  1.6937237,  1.5019817] #3.4 #5\n",
    "min_mag = 12\n",
    "max_mag = 23\n",
    "min_z = 0.0 #np.min(y_train) \n",
    "max_z = 1.1 #np.max(y_train) \n",
    "\n",
    "X_test, y_test, label_test, mask_cond = minmax_cutsOBSarr(X_test, y_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9950,)\n"
     ]
    }
   ],
   "source": [
    "resampleTrain = True\n",
    "\n",
    "if resampleTrain:\n",
    "    X_train, y_train, resampled_ind = resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of features in training data: (9950, 5)\n",
      "Size of output in training data: (9950,)\n",
      "Size of features in test data: (2767, 5)\n",
      "Size of output in test data: (2767,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of features in training data: {}\".format(X_train.shape))\n",
    "print(\"Size of output in training data: {}\".format(y_train.shape))\n",
    "print(\"Size of features in test data: {}\".format(X_test.shape))\n",
    "print(\"Size of output in test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "\n",
    "preproc = Pipeline([('stdscaler', StandardScaler())])\n",
    "# preproc = Pipeline([('stdscaler', MinMaxScaler())])\n",
    "X_train = preproc.fit_transform(X_train)\n",
    "\n",
    "scalerfile = save_mod + '_scaling_X'\n",
    "pickle.dump(preproc, open(scalerfile, 'wb'))\n",
    "preproc = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "\n",
    "X_test = preproc.transform(X_test)\n",
    "\n",
    "# preproc_y = Pipeline([('stdscaler', StandardScaler())])\n",
    "preproc_y = Pipeline([('stdscaler', MinMaxScaler())])\n",
    "\n",
    "\n",
    "y_train = preproc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "scalerfile = save_mod + '_scaling_y'\n",
    "pickle.dump(preproc_y, open(scalerfile, 'wb'))\n",
    "preproc_y = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "y_test = preproc_y.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "number of datapoints:  9950\n",
      "z-minmax:  0.0 0.99999994\n",
      "ColMag-min:  [-1.6409001 -2.280429  -2.1727188 -2.2547731 -4.2329054]\n",
      "ColMag-max:  [4.6897407 3.7267692 3.5270236 3.8686678 1.2576239]\n",
      "----------\n",
      "----------\n",
      "number of datapoints:  2767\n",
      "z-minmax:  -0.0016874264 0.8794259\n",
      "ColMag-min:  [-1.6361253 -2.2358537 -2.3130894 -2.3068612 -4.1867476]\n",
      "ColMag-max:  [4.7729926 4.186437  3.6221097 3.9470558 1.0187622]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print_limits(X_train, y_train)\n",
    "\n",
    "print_limits(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f10bbc21fd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(23)\n",
    "\n",
    "plt.hist(y_train, density=True, bins = 250, histtype='step', label='train')\n",
    "plt.hist(y_test, density=True, bins = 250, histtype='step', label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay(epoch):\n",
    "    if (epoch < 1):\n",
    "        return learning_rate\n",
    "    else:\n",
    "        return learning_rate*(1.0/(1.0+decay_rate*(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1, model_train.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.keras.layers.InputLayer(input_shape=(D,)),\n",
    "non_lin_act = tf.nn.relu #tf.nn.tanh\n",
    "y_true = tf.keras.Input(shape=(1,))\n",
    "inputs = tf.keras.Input(shape=(D,))\n",
    "layer_1 = tf.keras.layers.Dense(units=512, activation=non_lin_act)(inputs)\n",
    "layer_1a = tf.keras.layers.Dense(units=1024, activation=non_lin_act)(layer_1)\n",
    "layer_1b = tf.keras.layers.Dense(units=2048, activation=non_lin_act)(layer_1a)\n",
    "layer_1c = tf.keras.layers.Dense(units=1024, activation=non_lin_act)(layer_1b)\n",
    "layer_2 = tf.keras.layers.Dense(units=512, activation=non_lin_act)(layer_1c)\n",
    "layer_3 = tf.keras.layers.Dense(units=256, activation=non_lin_act)(layer_2)\n",
    "layer_4 = tf.keras.layers.Dense(units=128, activation=non_lin_act)(layer_3)\n",
    "layer_5 = tf.keras.layers.Dense(units=64, activation=non_lin_act)(layer_4)\n",
    "layer_6 = tf.keras.layers.Dense(units=32, activation=non_lin_act)(layer_5)\n",
    "mu = tf.keras.layers.Dense(units=K, activation=None, name=\"mu\")(layer_6)\n",
    "var = tf.keras.backend.exp(tf.keras.layers.Dense(units=K, activation=tf.nn.softplus, name=\"sigma\")(layer_6))\n",
    "pi = tf.keras.layers.Dense(units=K, activation=tf.nn.softmax, name=\"mixing\")(layer_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = Model([inputs, y_true], [mu, var, pi], name='mdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mdn\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          3072        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         525312      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         2099200     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          524800      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          131328      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           8256        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           2080        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sigma (Dense)                   (None, 3)            99          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 3)            99          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 3)            0           sigma[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mixing (Dense)                  (None, 3)            99          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (1, None)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_3 (TFOpLam (1, None)            0           tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_4 (TFOpLam (1, None)            0           tf.convert_to_tensor_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (2,)                 0           tf.convert_to_tensor_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_5 (TFOpLam (2,)                 0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (2,)                 0           tf.convert_to_tensor_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (0,)                 0           tf.convert_to_tensor_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (3,)                 0           tf.__operators__.getitem[0][0]   \n",
      "                                                                 tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (1, None, 1)         0           tf.convert_to_tensor_3[0][0]     \n",
      "                                                                 tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_2 (TFOpLam (None, 3)            0           tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_6 (TFOpLam (1, None, 1)         0           tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_7 (TFOpLam (None, 3)            0           tf.convert_to_tensor_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_1 (TFOpLam (None, 3)            0           mu[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (1, None, 3)         0           tf.convert_to_tensor_6[0][0]     \n",
      "                                                                 tf.convert_to_tensor_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_1 (TFOpLambda)  (None, 3)            0           tf.convert_to_tensor_1[0][0]     \n",
      "                                                                 tf.convert_to_tensor_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.squared_difference (TFO (1, None, 3)         0           tf.math.truediv[0][0]            \n",
      "                                                                 tf.math.truediv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.log (TFOpLambda)        (None, 3)            0           tf.convert_to_tensor_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (None, 3)            0           mixing[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (1, None, 3)         0           tf.math.squared_difference[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 3)            0           tf.math.log[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.log_1 (TFOpLambda)      (None, 3)            0           tf.convert_to_tensor[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (1, None, 3)         0           tf.math.multiply[0][0]           \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.log_softmax (TFOpLambda)  (None, 3)            0           tf.math.log_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (1, None, 3)         0           tf.math.subtract[0][0]           \n",
      "                                                                 tf.nn.log_softmax[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_logsumexp (TFOpL (1, None)            0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (1, None)            0           tf.math.reduce_logsumexp[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda ()                   0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf.math.reduce_mean[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 5,425,417\n",
      "Trainable params: 5,425,417\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define custom loss\n",
    "def custom_loss(layer):\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true, mu, var, pi):\n",
    "        mixture_distribution = tfp.distributions.Categorical(probs=pi)\n",
    "        distribution = tfp.distributions.Normal(loc=mu, scale=var)\n",
    "        likelihood = tfp.distributions.MixtureSameFamily(mixture_distribution=mixture_distribution,components_distribution=distribution)\n",
    "\n",
    "        log_likelihood = -1.0*likelihood.log_prob(tf.transpose(y_true))\n",
    "        mean_loss = tf.reduce_mean(log_likelihood)\n",
    "\n",
    "        return mean_loss\n",
    "   \n",
    "    return loss\n",
    "    \n",
    "\n",
    "model_train.add_loss(custom_loss(inputs)(y_true, mu, var, pi))\n",
    "\n",
    "model_train.compile(optimizer='Nadam')\n",
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/9 [=========>....................] - ETA: 0s - loss: 1.6442 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0118s). Check your callbacks.\n",
      "9/9 [==============================] - 2s 47ms/step - loss: 1.6342 - val_loss: 1.6502\n",
      "\n",
      "Learning rate for epoch 1 is 9.999999747378752e-05\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.4688 - val_loss: 1.0409\n",
      "\n",
      "Learning rate for epoch 2 is 9.990009857574478e-05\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.0388 - val_loss: 0.9685\n",
      "\n",
      "Learning rate for epoch 3 is 9.980039612855762e-05\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.9449 - val_loss: 0.9317\n",
      "\n",
      "Learning rate for epoch 4 is 9.970089740818366e-05\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.9395 - val_loss: 0.9305\n",
      "\n",
      "Learning rate for epoch 5 is 9.960159513866529e-05\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.9334 - val_loss: 0.9262\n",
      "\n",
      "Learning rate for epoch 6 is 9.95024893200025e-05\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.9291 - val_loss: 0.9261\n",
      "\n",
      "Learning rate for epoch 7 is 9.940357995219529e-05\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9244 - val_loss: 0.9250\n",
      "\n",
      "Learning rate for epoch 8 is 9.930486703524366e-05\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9308 - val_loss: 0.9456\n",
      "\n",
      "Learning rate for epoch 9 is 9.920635056914762e-05\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9277 - val_loss: 0.9219\n",
      "\n",
      "Learning rate for epoch 10 is 9.910803055390716e-05\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.9222 - val_loss: 0.9223\n",
      "\n",
      "Learning rate for epoch 11 is 9.900989971356466e-05\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9228 - val_loss: 0.9391\n",
      "\n",
      "Learning rate for epoch 12 is 9.891196532407776e-05\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9372 - val_loss: 0.9232\n",
      "\n",
      "Learning rate for epoch 13 is 9.881422738544643e-05\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9222 - val_loss: 0.9215\n",
      "\n",
      "Learning rate for epoch 14 is 9.871668589767069e-05\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9219 - val_loss: 0.9245\n",
      "\n",
      "Learning rate for epoch 15 is 9.86193263088353e-05\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9233 - val_loss: 0.9283\n",
      "\n",
      "Learning rate for epoch 16 is 9.85221704468131e-05\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9293 - val_loss: 0.9262\n",
      "\n",
      "Learning rate for epoch 17 is 9.842519648373127e-05\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9225 - val_loss: 0.9213\n",
      "\n",
      "Learning rate for epoch 18 is 9.832841897150502e-05\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9212 - val_loss: 0.9215\n",
      "\n",
      "Learning rate for epoch 19 is 9.823183063417673e-05\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9212 - val_loss: 0.9223\n",
      "\n",
      "Learning rate for epoch 20 is 9.81354241957888e-05\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9282 - val_loss: 0.9380\n",
      "\n",
      "Learning rate for epoch 21 is 9.803921420825645e-05\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9249 - val_loss: 0.9213\n",
      "\n",
      "Learning rate for epoch 22 is 9.794319339562207e-05\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9212 - val_loss: 0.9214\n",
      "\n",
      "Learning rate for epoch 23 is 9.784736175788566e-05\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9209 - val_loss: 0.9212\n",
      "\n",
      "Learning rate for epoch 24 is 9.775171201908961e-05\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9211 - val_loss: 0.9320\n",
      "\n",
      "Learning rate for epoch 25 is 9.765625145519152e-05\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9287 - val_loss: 0.9269\n",
      "\n",
      "Learning rate for epoch 26 is 9.756097279023379e-05\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9243 - val_loss: 0.9215\n",
      "\n",
      "Learning rate for epoch 27 is 9.746589057613164e-05\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9209 - val_loss: 0.9211\n",
      "\n",
      "Learning rate for epoch 28 is 9.737098298501223e-05\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9208 - val_loss: 0.9215\n",
      "\n",
      "Learning rate for epoch 29 is 9.72762645687908e-05\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9208 - val_loss: 0.9218\n",
      "\n",
      "Learning rate for epoch 30 is 9.718172805150971e-05\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9235 - val_loss: 0.9431\n",
      "\n",
      "Learning rate for epoch 31 is 9.708738070912659e-05\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9299 - val_loss: 0.9212\n",
      "\n",
      "Learning rate for epoch 32 is 9.699320798972622e-05\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9209 - val_loss: 0.9211\n",
      "\n",
      "Learning rate for epoch 33 is 9.689922444522381e-05\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9207 - val_loss: 0.9211\n",
      "\n",
      "Learning rate for epoch 34 is 9.680542279966176e-05\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9206 - val_loss: 0.9215\n",
      "\n",
      "Learning rate for epoch 35 is 9.671179577708244e-05\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9223 - val_loss: 0.9346\n",
      "\n",
      "Learning rate for epoch 36 is 9.66183579294011e-05\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9264 - val_loss: 0.9215\n",
      "\n",
      "Learning rate for epoch 37 is 9.65250947047025e-05\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9213 - val_loss: 0.9214\n",
      "\n",
      "Learning rate for epoch 38 is 9.643201337894425e-05\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9206 - val_loss: 0.9209\n",
      "\n",
      "Learning rate for epoch 39 is 9.633911395212635e-05\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9205 - val_loss: 0.9221\n",
      "\n",
      "Learning rate for epoch 40 is 9.62463891482912e-05\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9215 - val_loss: 0.9263\n",
      "\n",
      "Learning rate for epoch 41 is 9.61538462433964e-05\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9262 - val_loss: 0.9250\n",
      "\n",
      "Learning rate for epoch 42 is 9.606147796148434e-05\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9216 - val_loss: 0.9209\n",
      "\n",
      "Learning rate for epoch 43 is 9.596929157851264e-05\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9205 - val_loss: 0.9214\n",
      "\n",
      "Learning rate for epoch 44 is 9.587727981852368e-05\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9205 - val_loss: 0.9208\n",
      "\n",
      "Learning rate for epoch 45 is 9.578544268151745e-05\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9206 - val_loss: 0.9250\n",
      "\n",
      "Learning rate for epoch 46 is 9.569378016749397e-05\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9239 - val_loss: 0.9252\n",
      "\n",
      "Learning rate for epoch 47 is 9.560229227645323e-05\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9237 - val_loss: 0.9217\n",
      "\n",
      "Learning rate for epoch 48 is 9.551098628435284e-05\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9205 - val_loss: 0.9208\n",
      "\n",
      "Learning rate for epoch 49 is 9.541984763927758e-05\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9203 - val_loss: 0.9208\n",
      "\n",
      "Learning rate for epoch 50 is 9.532888361718506e-05\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9205 - val_loss: 0.9224\n",
      "\n",
      "Learning rate for epoch 51 is 9.523809421807528e-05\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9213 - val_loss: 0.9247\n",
      "\n",
      "Learning rate for epoch 52 is 9.514747944194824e-05\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9249 - val_loss: 0.9249\n",
      "\n",
      "Learning rate for epoch 53 is 9.505703201284632e-05\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9214 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 54 is 9.496675920672715e-05\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9203 - val_loss: 0.9212\n",
      "\n",
      "Learning rate for epoch 55 is 9.487666102359071e-05\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9203 - val_loss: 0.9211\n",
      "\n",
      "Learning rate for epoch 56 is 9.47867301874794e-05\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9206 - val_loss: 0.9238\n",
      "\n",
      "Learning rate for epoch 57 is 9.469696669839323e-05\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9229 - val_loss: 0.9253\n",
      "\n",
      "Learning rate for epoch 58 is 9.460737783228979e-05\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9231 - val_loss: 0.9215\n",
      "\n",
      "Learning rate for epoch 59 is 9.451795631321147e-05\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9203 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 60 is 9.44287094171159e-05\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9201 - val_loss: 0.9209\n",
      "\n",
      "Learning rate for epoch 61 is 9.433962259208784e-05\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9201 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 62 is 9.425071039004251e-05\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9208 - val_loss: 0.9288\n",
      "\n",
      "Learning rate for epoch 63 is 9.41619582590647e-05\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9249 - val_loss: 0.9235\n",
      "\n",
      "Learning rate for epoch 64 is 9.407338075106964e-05\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9217 - val_loss: 0.9209\n",
      "\n",
      "Learning rate for epoch 65 is 9.398496331414208e-05\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9201 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 66 is 9.389671322423965e-05\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9200 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 67 is 9.380863048136234e-05\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9200 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 68 is 9.372071508551016e-05\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9206 - val_loss: 0.9281\n",
      "\n",
      "Learning rate for epoch 69 is 9.36329597607255e-05\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9248 - val_loss: 0.9216\n",
      "\n",
      "Learning rate for epoch 70 is 9.354537178296596e-05\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9207 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 71 is 9.345794387627393e-05\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9200 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 72 is 9.337068331660703e-05\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9200 - val_loss: 0.9210\n",
      "\n",
      "Learning rate for epoch 73 is 9.328358282800764e-05\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9201 - val_loss: 0.9209\n",
      "\n",
      "Learning rate for epoch 74 is 9.319664241047576e-05\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9209 - val_loss: 0.9287\n",
      "\n",
      "Learning rate for epoch 75 is 9.310986933996901e-05\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9238 - val_loss: 0.9215\n",
      "\n",
      "Learning rate for epoch 76 is 9.302325634052977e-05\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.9208 - val_loss: 0.9208\n",
      "\n",
      "Learning rate for epoch 77 is 9.293680341215804e-05\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9200 - val_loss: 0.9205\n",
      "\n",
      "Learning rate for epoch 78 is 9.285051055485383e-05\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.9200 - val_loss: 0.9209\n",
      "\n",
      "Learning rate for epoch 79 is 9.276437776861712e-05\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9200 - val_loss: 0.9216\n",
      "\n",
      "Learning rate for epoch 80 is 9.267840505344793e-05\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9220 - val_loss: 0.9301\n",
      "\n",
      "Learning rate for epoch 81 is 9.259259240934625e-05\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9235 - val_loss: 0.9206\n",
      "\n",
      "Learning rate for epoch 82 is 9.250693983631209e-05\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9202 - val_loss: 0.9208\n",
      "\n",
      "Learning rate for epoch 83 is 9.242144005838782e-05\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9200 - val_loss: 0.9205\n",
      "\n",
      "Learning rate for epoch 84 is 9.233610035153106e-05\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9199 - val_loss: 0.9210\n",
      "\n",
      "Learning rate for epoch 85 is 9.225092071574181e-05\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9201 - val_loss: 0.9213\n",
      "\n",
      "Learning rate for epoch 86 is 9.216590115102008e-05\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9220 - val_loss: 0.9275\n",
      "\n",
      "Learning rate for epoch 87 is 9.208103438140824e-05\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9224 - val_loss: 0.9210\n",
      "\n",
      "Learning rate for epoch 88 is 9.19963204069063e-05\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9204 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 89 is 9.191176650347188e-05\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9199 - val_loss: 0.9217\n",
      "\n",
      "Learning rate for epoch 90 is 9.182736539514735e-05\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.9201 - val_loss: 0.9206\n",
      "\n",
      "Learning rate for epoch 91 is 9.174311708193272e-05\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9205 - val_loss: 0.9225\n",
      "\n",
      "Learning rate for epoch 92 is 9.16590288397856e-05\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9211 - val_loss: 0.9217\n",
      "\n",
      "Learning rate for epoch 93 is 9.157509339274839e-05\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9213 - val_loss: 0.9216\n",
      "\n",
      "Learning rate for epoch 94 is 9.149131074082106e-05\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9203 - val_loss: 0.9205\n",
      "\n",
      "Learning rate for epoch 95 is 9.140768088400364e-05\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9200 - val_loss: 0.9208\n",
      "\n",
      "Learning rate for epoch 96 is 9.132420382229611e-05\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9201 - val_loss: 0.9218\n",
      "\n",
      "Learning rate for epoch 97 is 9.124087227974087e-05\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9214 - val_loss: 0.9282\n",
      "\n",
      "Learning rate for epoch 98 is 9.115770080825314e-05\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.9230 - val_loss: 0.9205\n",
      "\n",
      "Learning rate for epoch 99 is 9.10746821318753e-05\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.9200 - val_loss: 0.9207\n",
      "\n",
      "Learning rate for epoch 100 is 9.099180897464976e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if train_mode:\n",
    "\n",
    "    history = model_train.fit([X_train, y_train], validation_split = 0.1, epochs=n_epochs, batch_size = batch_size, callbacks=callbacks)\n",
    "\n",
    "\n",
    "    model_train.save_weights(save_mod + '.h5')\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], 'r')\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.xlabel('Epochs', fontsize = 28)\n",
    "    plt.ylabel('Loss', fontsize = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_train.load_weights(save_mod + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1,5,1] vs. [2767,3] [Op:RealDiv]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-70d7ba5e2e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_arg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_arg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# multiple ops w/ the same name when the layer is reused)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m   \"\"\"\n\u001b[0;32m-> 1336\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1273\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   7327\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7329\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7330\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7331\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_v100/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,5,1] vs. [2767,3] [Op:RealDiv]"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(model_train(  X_test, np.zeros(shape = X_test.shape[1]) ))\n",
    "\n",
    "y_pred_arg = np.argmax(y_pred[2, :, :], axis = 1)\n",
    "y_pred_mean = y_pred[0, :, :][:, y_pred_arg][:, 0]\n",
    "y_pred_std = np.sqrt(np.log(y_pred[1, :, :][:, y_pred_arg][:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3means = preproc_y.inverse_transform(y_pred[0, :, :])\n",
    "y_pred_3std = preproc_y.inverse_transform( np.sqrt(np.log(y_pred[1, :, :])  ))\n",
    "y_pred_3weights = y_pred[2, :, :]\n",
    "\n",
    "y_test_all = preproc_y.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "predstdweights = np.array([y_pred_3means, y_pred_3std, y_pred_3weights])\n",
    "truelabel = np.array([y_test_all[:, 0], label_test])\n",
    "\n",
    "np.save(save_mod+'test_true', predstdweights )\n",
    "np.save(save_mod+'test_pred', truelabel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifPlotWeighted = True\n",
    "y_pred_mean_best = y_pred_mean\n",
    "y_pred_std_best = y_pred_std\n",
    "\n",
    "if ifPlotWeighted:\n",
    "    \n",
    "\n",
    "    colorstring = ['b', 'r', 'g', 'k', 'orange']\n",
    "    surveystring = ['SDSS', 'VIPERS', 'DEEP2']\n",
    "\n",
    "    plt.figure(22, figsize=(10, 10,))\n",
    "\n",
    "    C = 0.05\n",
    "    z_t = np.array([0, 1])\n",
    "    z_tp = z_t + C*(1+z_t)\n",
    "    z_tm = z_t - C*(1+z_t)\n",
    "\n",
    "    plt.plot(z_t, z_t, 'k')\n",
    "    plt.plot(z_t, z_tp, 'k-.')\n",
    "    plt.plot(z_t, z_tm, 'k-.')\n",
    "\n",
    "    for label_ind in [0, 1, 2]:\n",
    "        surveyindx = np.where(label_test == label_ind)\n",
    "        offset = 0.0\n",
    "        \n",
    "        plt.errorbar(preproc_y.inverse_transform(y_test)[surveyindx][:, 0], offset + preproc_y.inverse_transform(y_pred_mean_best.reshape(-1, 1))[surveyindx][:, 0], yerr= preproc_y.inverse_transform(y_pred_std_best.reshape(-1, 1))[surveyindx][:, 0], fmt = 'o', marker=None, ms = 4, alpha = 0.3, label = 'Training: Synthetic, Testing: '+surveystring[label_ind], c = colorstring[label_ind])\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel(r'$z_{phot}$', fontsize=25)\n",
    "plt.xlabel(r'$z_{spec}$', fontsize=25)\n",
    "        \n",
    "plt.xlim(0.0, 1)\n",
    "plt.ylim(0.0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.axes().set_aspect('equal')\n",
    "\n",
    "leg = plt.legend(fontsize = 'xx-large', markerscale=1., numpoints=2)\n",
    "plt.savefig('phoz_compare_surveys.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
