{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras.models import load_model, Sequential, Model\n",
    "\n",
    "np.random.seed(12211)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 200000\n",
    "num_test = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainset = ['FSPSlin', 'FSPSlog', 'FSPSall', 'OBS', 'UM', 'BP', 'UMnew'][6]#6\n",
    "Testset = ['FSPSlin', 'FSPSlog', 'FSPSall', 'OBS', 'UM', 'BP', 'UMnew'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000 #20\n",
    "D = 5 \n",
    "K = 3\n",
    "\n",
    "learning_rate = 1e-5\n",
    "decay_rate= 1e-3 \n",
    "batch_size = 1024 \n",
    "\n",
    "save_mod = 'saved_hubs/tf2models/'+'Train_'+Trainset+'_lr_'+str(learning_rate)+'_dr'+str(decay_rate)+'_ne'+str(n_epochs)+'_k'+str(K)+'_nt'+str(num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_cutsOBSarr(X, y, l):\n",
    "    # print(X.shape)\n",
    "    \n",
    "    mask_cond =  np.where( \n",
    "        (X[:, 0] < max_col[0]) & (X[:, 0] > min_col[0]) &\n",
    "        (X[:, 1] < max_col[1]) & (X[:, 1] > min_col[1]) &\n",
    "        (X[:, 2] < max_col[2]) & (X[:, 2] > min_col[2]) &\n",
    "        (X[:, 3] < max_col[3]) & (X[:, 3] > min_col[3]) & \n",
    "        (X[:, 4] < max_mag) & (X[:, 4] > min_mag) &\n",
    "        (y < max_z) & (y > min_z) )\n",
    "    \n",
    "    # print( np.array(mask_cond).shape)\n",
    "\n",
    "    X_new = X[mask_cond]\n",
    "    y_new = y[mask_cond]\n",
    "    l_new = l[mask_cond]\n",
    "    # print(X_new.shape)\n",
    "    return X_new, y_new, l_new, mask_cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_limits(X, y):\n",
    "    print(10*'-')\n",
    "    print('number of datapoints: ', str(y.shape[0]))\n",
    "    print('z-minmax: ', y.min(), y.max())\n",
    "    print('ColMag-min: ', np.min(X, axis=0))\n",
    "    print('ColMag-max: ', np.max(X, axis=0))\n",
    "    print(10*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    shuffleOrder = np.arange(X.shape[0])\n",
    "    np.random.shuffle(shuffleOrder)\n",
    "    X = X[shuffleOrder]\n",
    "    y = y[shuffleOrder]\n",
    "    return X, y, shuffleOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainTest(dirIn = '../../Data/fromGalaxev/photozs/datasets/data_may_2020/'):\n",
    "    \n",
    "    test_data = np.load(dirIn + 'test_' + Testset +'.npy') \n",
    "\n",
    "    X_test = test_data[: , :-1]\n",
    "    y_test = test_data[: , -1]\n",
    "\n",
    "    print_limits(X_test, y_test)\n",
    "\n",
    "    if Testset == 'OBS':\n",
    "        test_labels = np.load(dirIn + 'test_' + Testset + '_label.npy') \n",
    "\n",
    "    return _, _, X_test, y_test, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, X_test, y_test, label_test = loadTrainTest(dirIn = 'Data/fromGalaxev/photozs/datasets/data_may_2020/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_col = [-0.09145837, -0.05327791, -0.02479261, -0.10519464] #-0.03 #-5\n",
    "max_col = [ 3.825315,   2.8303378,  1.6937237,  1.5019817] #3.4 #5\n",
    "min_mag = 12\n",
    "max_mag = 23\n",
    "min_z = 0.0 #np.min(y_train) \n",
    "max_z = 1.1 #np.max(y_train) \n",
    "\n",
    "\n",
    "X_test, y_test, label_test, mask_cond = minmax_cutsOBSarr(X_test, y_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Size of features in test data: {}\".format(X_test.shape))\n",
    "print(\"Size of output in test data: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preproc = Pipeline([('stdscaler', StandardScaler())])\n",
    "scalerfile = save_mod + '_scaling_X'\n",
    "preproc = pickle.load(open(scalerfile, 'rb'))\n",
    "X_test = preproc.transform(X_test)\n",
    "\n",
    "\n",
    "preproc_y = Pipeline([('stdscaler', MinMaxScaler())])\n",
    "scalerfile = save_mod + '_scaling_y'\n",
    "preproc_y = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "\n",
    "y_test = preproc_y.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(23)\n",
    "\n",
    "plt.hist(y_test, density=True, bins = 250, histtype='step', label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_lin_act = tf.nn.relu #tf.nn.tanh\n",
    "y_true = tf.keras.Input(shape=(1,))\n",
    "inputs = tf.keras.Input(shape=(D,))\n",
    "layer_1 = tf.keras.layers.Dense(units=512, activation=non_lin_act)(inputs)\n",
    "layer_1a = tf.keras.layers.Dense(units=1024, activation=non_lin_act)(layer_1)\n",
    "layer_1b = tf.keras.layers.Dense(units=2048, activation=non_lin_act)(layer_1a)\n",
    "layer_1c = tf.keras.layers.Dense(units=1024, activation=non_lin_act)(layer_1b)\n",
    "layer_2 = tf.keras.layers.Dense(units=512, activation=non_lin_act)(layer_1c)\n",
    "layer_3 = tf.keras.layers.Dense(units=256, activation=non_lin_act)(layer_2)\n",
    "layer_4 = tf.keras.layers.Dense(units=128, activation=non_lin_act)(layer_3)\n",
    "layer_5 = tf.keras.layers.Dense(units=64, activation=non_lin_act)(layer_4)\n",
    "layer_6 = tf.keras.layers.Dense(units=32, activation=non_lin_act)(layer_5)\n",
    "mu = tf.keras.layers.Dense(units=K, activation=None, name=\"mu\")(layer_6)\n",
    "var = tf.keras.backend.exp(tf.keras.layers.Dense(units=K, activation=tf.nn.softplus, name=\"sigma\")(layer_6))\n",
    "pi = tf.keras.layers.Dense(units=K, activation=tf.nn.softmax, name=\"mixing\")(layer_6)\n",
    "\n",
    "model_train = Model([inputs, y_true], [mu, var, pi], name='mdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define custom loss\n",
    "def custom_loss(layer):\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true, mu, var, pi):\n",
    "        mixture_distribution = tfp.distributions.Categorical(probs=pi)\n",
    "        distribution = tfp.distributions.Normal(loc=mu, scale=var)\n",
    "        likelihood = tfp.distributions.MixtureSameFamily(mixture_distribution=mixture_distribution,components_distribution=distribution)\n",
    "\n",
    "        log_likelihood = -1.0*likelihood.log_prob(tf.transpose(y_true))\n",
    "        mean_loss = tf.reduce_mean(log_likelihood)\n",
    "\n",
    "        return mean_loss\n",
    "    return loss\n",
    "    \n",
    "# Compile the model\n",
    "model_train.add_loss(custom_loss(inputs)(y_true, mu, var, pi))\n",
    "\n",
    "\n",
    "model_train.compile(optimizer='adam')\n",
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_train.load_weights(save_mod + '.h5')\n",
    "\n",
    "y_pred = np.array(model_train(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_arg = np.argmax(y_pred[2, :, :], axis = 1)\n",
    "y_pred_mean = y_pred[0, :, :][:, y_pred_arg][:, 0]\n",
    "y_pred_std = np.sqrt(np.log(y_pred[1, :, :][:, y_pred_arg][:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3means = preproc_y.inverse_transform(y_pred[0, :, :])\n",
    "y_pred_3std = preproc_y.inverse_transform( np.sqrt(np.log(y_pred[1, :, :])  ))\n",
    "y_pred_3weights = y_pred[2, :, :]\n",
    "\n",
    "y_test_all = preproc_y.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "predstdweights = np.array([y_pred_3means, y_pred_3std, y_pred_3weights])\n",
    "truelabel = np.array([y_test_all[:, 0], label_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ifPlotWeighted = True\n",
    "y_pred_mean_best = y_pred_mean\n",
    "y_pred_std_best = y_pred_std\n",
    "\n",
    "\n",
    "if ifPlotWeighted:\n",
    "    plt.figure(22, figsize=(10, 10))\n",
    "\n",
    "\n",
    "    plt.errorbar(preproc_y.inverse_transform(y_test)[:, 0], preproc_y.inverse_transform(y_pred_mean_best.reshape(-1, 1))[:, 0], yerr= preproc_y.inverse_transform(y_pred_std_best.reshape(-1, 1) )[:, 0], fmt='ro', ecolor='k', ms = 5, alpha = 0.1, label = 'Training with synthetic data')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k')\n",
    "plt.plot([0, 1], 0.85*np.array([0, 1]), 'k-.')\n",
    "plt.plot([0, 1], 1.15*np.array([0, 1]), 'k-.')\n",
    "\n",
    "\n",
    "plt.ylabel(r'Photometric redshift', fontsize=25)\n",
    "plt.xlabel(r'True redshift', fontsize=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "\n",
    "leg = plt.legend(fontsize = 'xx-large', markerscale=1., numpoints=2)\n",
    "\n",
    "for artist, text in zip(leg.legendHandles, leg.get_texts()):\n",
    "    col = artist.get_color()\n",
    "    if isinstance(col, np.ndarray):\n",
    "        col = col[0]\n",
    "    text.set_color(col)\n",
    "    text.set_alpha(1.0)\n",
    "\n",
    "\n",
    "# plt.savefig('phoz_compare.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ifPlotWeighted = True\n",
    "\n",
    "if ifPlotWeighted:\n",
    "    \n",
    "\n",
    "    colorstring = ['b', 'r', 'g', 'k', 'orange']\n",
    "    surveystring = ['Primus', 'Vipers', 'SDSS', 'DEEP2', 'Wiggle-z']\n",
    "\n",
    "\n",
    "    for label_ind in [0, 1, 2, 3, 4]:\n",
    "\n",
    "        plt.figure(22, figsize=(10, 10,))\n",
    "\n",
    "        surveyindx = np.where(label_test == label_ind)\n",
    "\n",
    "        offset = 0.04\n",
    "        \n",
    "        plt.errorbar(preproc_y.inverse_transform(y_test)[surveyindx][:, 0], offset + preproc_y.inverse_transform(y_pred_mean_best.reshape(-1, 1))[surveyindx][:, 0], yerr= preproc_y.inverse_transform(y_pred_std_best.reshape(-1, 1))[surveyindx][:, 0], fmt = 'o', marker=None, ms = 4, alpha = 0.3, label = 'Training: Synthetic, Testing: '+surveystring[label_ind], c = colorstring[label_ind])\n",
    "\n",
    "\n",
    "        C = 0.05\n",
    "        z_t = np.array([0, 1])\n",
    "        z_tp = z_t + C*(1+z_t)\n",
    "        z_tm = z_t - C*(1+z_t)\n",
    "\n",
    "        plt.plot(z_t, z_t, 'k')\n",
    "\n",
    "\n",
    "\n",
    "        plt.plot(z_t, z_tp, 'k-.')\n",
    "        plt.plot(z_t, z_tm, 'k-.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        plt.ylabel(r'$z_{phot}$', fontsize=25)\n",
    "        plt.xlabel(r'$z_{spec}$', fontsize=25)\n",
    "        \n",
    "        plt.xlim(0.0, 1)\n",
    "        plt.ylim(0.0, 1)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.axes().set_aspect('equal')\n",
    "\n",
    "\n",
    "        leg = plt.legend(fontsize = 'xx-large', markerscale=1., numpoints=2)\n",
    "\n",
    "        trueprederr = np.array([preproc_y.inverse_transform(y_test)[surveyindx], offset + (preproc_y.inverse_transform(y_pred_mean_best.reshape(-1, 1))[surveyindx]), preproc_y.inverse_transform(y_pred_std_best.reshape(-1, 1))[surveyindx]])\n",
    "#         np.save(save_mod + 'test_label_' +str(label_ind), trueprederr)\n",
    "\n",
    "\n",
    "\n",
    "# plt.savefig('phoz_compare_surveys.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('env_py37': conda)",
   "language": "python",
   "name": "python37564bitenvpy37conda17150a11545f4ac4a3ea6d7b215219bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
